{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, Table, Column, Float, String, MetaData\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing area\n",
    "# initial testing with a single page before using loops later on. Using soup to find and scrape the values I was looking for\n",
    "\n",
    "# browser = Browser('edge')\n",
    "#url = \"https://www.canadiantire.ca/en/promotions/clearance.html?page=20\"\n",
    "# browser.visit(url)\n",
    "#html = browser.html\n",
    "#html_soup = soup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing area\n",
    "\n",
    "# product_info = html_soup.find_all(class_='nl-product__content')\n",
    "# product_data1 = []\n",
    "\n",
    "# for product in product_info:\n",
    "#     product_name_element = product.find('div', class_='nl-product-card__title')\n",
    "#     original_price_element = product.find('s', attrs={'aria-hidden': 'true'})\n",
    "#     clearance_price_element = product.find('span', class_='nl-price--total--red')\n",
    "#     rating_element = product.find('div', class_='bv_text')\n",
    "#     image_element = product.find('div', class_='nl-product-card__image-wrap')\n",
    "#     anchor_tag = product.find('a', class_='nl-product-card__no-button', href=True)\n",
    "#     img_tag = product.find('img', attrs={'data-src': True})\n",
    "\n",
    "#     product_name = product_name_element.text.strip() if product_name_element else 'N/A'\n",
    "#     original_price = original_price_element.text.strip() if original_price_element else 'N/A'\n",
    "#     clearance_price = clearance_price_element.text.strip() if clearance_price_element else 'N/A'\n",
    "#     rating = rating_element.text.strip() if rating_element else None\n",
    "#     product_code_element = product.find('p', class_='nl-product__code', attrs={'aria-hidden': 'true'})\n",
    "#     product_code = product_code_element.get_text(strip=True).lstrip('#') if product_code_element else 'N/A'\n",
    "#     product_link = \"https://www.canadiantire.ca\" + anchor_tag['href'] if anchor_tag is not None else 'N/A'\n",
    "#     product_image_link = img_tag['data-src'] if img_tag and 'data-src' in img_tag.attrs else 'N/A'\n",
    "\n",
    "#     if original_price == 'N/A':\n",
    "#         alt_original_price_element = product.find('span', class_='nl-price--total')\n",
    "#         original_price = alt_original_price_element.text.strip() if alt_original_price_element else 'N/A'\n",
    "\n",
    "#     clearance_price = float(clearance_price.replace('Each', '').replace('$', '').replace(',', '')) if clearance_price != 'N/A' else None\n",
    "#     original_price = float(original_price.replace('Each', '').replace('$', '').replace(',', '')) if original_price != 'N/A' else None\n",
    "\n",
    "#     product_data1.append({\n",
    "#         'Product Name': product_name,\n",
    "#         'Original Price': original_price,\n",
    "#         'Clearance Price': clearance_price,\n",
    "#         'Rating': rating,\n",
    "#         'Product Code': product_code,\n",
    "#         'Link': product_link,\n",
    "#         'Image Link': product_image_link\n",
    "#     })\n",
    "\n",
    "# print(product_data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing area\n",
    "\n",
    "# df1 = pd.DataFrame(product_data1)\n",
    "# df1.sample(24)\n",
    "# df1['Percentage Off'] = round(((df1['Original Price'] - df1['Clearance Price']) / df1['Original Price']) * 100)\n",
    "# df1.sample(24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing area\n",
    "\n",
    "# setup urlparse to grab the product category from the image link.\n",
    "\n",
    "# def extract_category(link_url):\n",
    "#     parsed_url = urlparse(link_url)\n",
    "#     path_components = parsed_url.path.split('/')\n",
    "#     category = '/'.join(path_components[3:4])\n",
    "#     return category\n",
    "\n",
    "# df1['Product Category'] = df1['Image Link'].apply(extract_category)\n",
    "\n",
    "# df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing the base url from the clearance section\n",
    "\n",
    "base_url = \"https://www.canadiantire.ca/en/promotions/clearance.html?page=\"\n",
    "\n",
    "# setting up some options for the chrome browser. Using the exp_option to click the allow location, and incognito mode to\n",
    "# seperate the browers from my other open browsers. Also, repeat testing without cookies saved was helpful.\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"profile.default_content_setting_values.geolocation\": 1\n",
    "})\n",
    "\n",
    "# setup the Chromedriver. it was not working without the time delay, perhaps letting the page load fully.\n",
    "service = Service(\n",
    "    \"C:\\Program Files\\Common Files\\ChromeDriver\\chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "driver.get(base_url)\n",
    "time.sleep(5)\n",
    "html_content = driver.page_source\n",
    "html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "# I wanted to dynamically determine the number of loops to use. I judged that total results, or total number of\n",
    "# products on sale, divided by the default number of products per page worked well. Using math.ceil to always round up.\n",
    "\n",
    "total_results_element = html_soup.find('span', class_='nl-filters__results')\n",
    "total_results_text = total_results_element.text if total_results_element else '0'\n",
    "# using re to extract the first sequence of digits found in the total_results_text\n",
    "# and store it in the variable total_results as an integer.\n",
    "total_results = int(re.search(r'\\d+', total_results_text).group())\n",
    "# default number of products per page\n",
    "items_per_page = 24\n",
    "total_pages = math.ceil(total_results / items_per_page)\n",
    "\n",
    "\n",
    "# creating a empty list to store data\n",
    "product_data = []\n",
    "\n",
    "\n",
    "# beginning the loop, adding time for the page to load, using a try except to handle a random survey pop-up.\n",
    "\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    url = base_url + str(page_number)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "# handle seemingly random survey pop-up\n",
    "    try:\n",
    "        not_right_now_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"kplDeclineButton\"))\n",
    "        )\n",
    "        not_right_now_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# gathering the ingredients for my delicious sales soup.\n",
    "\n",
    "    html_content = driver.page_source\n",
    "    html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "    product_info = html_soup.find_all(class_='nl-product__content')\n",
    "\n",
    "# another loop to grab all the info on the page. The first code chunk locates, the second chunk parses out.\n",
    "    for product in product_info:\n",
    "        product_name_element = product.find(\n",
    "            'div', class_='nl-product-card__title')\n",
    "        original_price_element = product.find(\n",
    "            's', attrs={'aria-hidden': 'true'})\n",
    "        clearance_price_element = product.find(\n",
    "            'span', class_='nl-price--total--red')\n",
    "        rating_element = product.find('div', class_='bv_text')\n",
    "        image_element = product.find(\n",
    "            'div', class_='nl-product-card__image-wrap')\n",
    "        anchor_tag = product.find(\n",
    "            'a', class_='nl-product-card__no-button', href=True)\n",
    "        img_tag = product.find('img', attrs={'data-src': True})\n",
    "\n",
    "        product_name = product_name_element.text.strip() if product_name_element else 'N/A'\n",
    "        original_price = original_price_element.text.strip(\n",
    "        ) if original_price_element else 'N/A'\n",
    "        clearance_price = clearance_price_element.text.strip(\n",
    "        ) if clearance_price_element else 'N/A'\n",
    "        rating = rating_element.text.strip() if rating_element else None\n",
    "        product_code_element = product.find(\n",
    "            'p', class_='nl-product__code', attrs={'aria-hidden': 'true'})\n",
    "        product_code = product_code_element.get_text(\n",
    "            strip=True).lstrip('#') if product_code_element else 'N/A'\n",
    "        product_link = \"https://www.canadiantire.ca\" + \\\n",
    "            anchor_tag['href'] if anchor_tag is not None else 'N/A'\n",
    "        product_image_link = img_tag['data-src'] if img_tag and 'data-src' in img_tag.attrs else 'N/A'\n",
    "\n",
    "# there were some products with prices in different places, so this fills in those spaces.\n",
    "        if original_price == 'N/A':\n",
    "            alt_original_price_element = product.find(\n",
    "                'span', class_='nl-price--total')\n",
    "            original_price = alt_original_price_element.text.strip(\n",
    "            ) if alt_original_price_element else 'N/A'\n",
    "\n",
    "# adding some data cleaning and parsing to the loop to make it easier later on.\n",
    "        clearance_price = float(clearance_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if clearance_price != 'N/A' else None\n",
    "        original_price = float(original_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if original_price != 'N/A' else None\n",
    "\n",
    "        product_data.append({\n",
    "            'Product Name': product_name,\n",
    "            'Original Price': original_price,\n",
    "            'Clearance Price': clearance_price,\n",
    "            'Rating': rating,\n",
    "            'Product Code': product_code,\n",
    "            'Link': product_link,\n",
    "            'Image Link': product_image_link\n",
    "        })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# printing these as a way to check that the scraping was working and how many deals there were\n",
    "print(f\"Total number of results: {total_results}\")\n",
    "print(f\"Total number of pages: {total_pages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wasn't actually interested in the image links as image links, but rather to parse out product category information,\n",
    "# which didn't seem to be present anywhere else on the page. I created a function that uses urllib.parse from urlparse\n",
    "# to grab the information that I wanted. I was having trouble getting re to work here, and this was simpler.\n",
    "\n",
    "def extract_category(link_url):\n",
    "    parsed_url = urlparse(link_url)\n",
    "    path_components = parsed_url.path.split('/')\n",
    "    category = '/'.join(path_components[3:4])\n",
    "    return category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframe, creating a new column that calculates the clearance prices, applying my extract_category\n",
    "clearance_df = pd.DataFrame(product_data)\n",
    "clearance_df['Percentage Off'] = round(\n",
    "    ((clearance_df['Original Price'] - clearance_df['Clearance Price']) / clearance_df['Original Price']) * 100)\n",
    "clearance_df['Product Category'] = clearance_df['Image Link'].apply(\n",
    "    extract_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOT-SALE scraping. Code is nearly idential to the above.\n",
    "# scraping the sale section for additional data\n",
    "\n",
    "base_url = \"https://www.canadiantire.ca/en/promotions/hot-sale.html?page=\"\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"profile.default_content_setting_values.geolocation\": 1\n",
    "})\n",
    "\n",
    "service = Service(\n",
    "    \"C:\\Program Files\\Common Files\\ChromeDriver\\chromedriver.exe\")\n",
    "driver2 = webdriver.Chrome(service=service)\n",
    "\n",
    "driver2.get(base_url)\n",
    "time.sleep(5)\n",
    "html_content = driver2.page_source\n",
    "html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "total_results_element = html_soup.find('span', class_='nl-filters__results')\n",
    "total_results_text = total_results_element.text if total_results_element else '0'\n",
    "\n",
    "total_results = int(re.search(r'\\d+', total_results_text).group())\n",
    "\n",
    "items_per_page = 24\n",
    "total_pages = math.ceil(total_results / items_per_page)\n",
    "\n",
    "sale_product_data = []\n",
    "\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    url = base_url + str(page_number)\n",
    "    driver2.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        not_right_now_button = WebDriverWait(driver2, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"kplDeclineButton\"))\n",
    "        )\n",
    "        not_right_now_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    html_content = driver2.page_source\n",
    "    html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "    sale_product_info = html_soup.find_all(class_='nl-product__content')\n",
    "\n",
    "    for product in sale_product_info:\n",
    "        product_name_element = product.find(\n",
    "            'div', class_='nl-product-card__title')\n",
    "        original_price_element = product.find(\n",
    "            's', attrs={'aria-hidden': 'true'})\n",
    "        clearance_price_element = product.find(\n",
    "            'span', class_='nl-price--total--red')\n",
    "        rating_element = product.find('div', class_='bv_text')\n",
    "        image_element = product.find(\n",
    "            'div', class_='nl-product-card__image-wrap')\n",
    "        anchor_tag = product.find(\n",
    "            'a', class_='nl-product-card__no-button', href=True)\n",
    "        img_tag = product.find('img', attrs={'data-src': True})\n",
    "\n",
    "        product_name = product_name_element.text.strip() if product_name_element else 'N/A'\n",
    "        original_price = original_price_element.text.strip(\n",
    "        ) if original_price_element else 'N/A'\n",
    "        clearance_price = clearance_price_element.text.strip(\n",
    "        ) if clearance_price_element else 'N/A'\n",
    "        rating = rating_element.text.strip() if rating_element else None\n",
    "        product_code_element = product.find(\n",
    "            'p', class_='nl-product__code', attrs={'aria-hidden': 'true'})\n",
    "        product_code = product_code_element.get_text(\n",
    "            strip=True).lstrip('#') if product_code_element else 'N/A'\n",
    "        product_link = \"https://www.canadiantire.ca\" + \\\n",
    "            anchor_tag['href'] if anchor_tag is not None else 'N/A'\n",
    "        product_image_link = img_tag['data-src'] if img_tag and 'data-src' in img_tag.attrs else 'N/A'\n",
    "\n",
    "        if original_price == 'N/A':\n",
    "            alt_original_price_element = product.find(\n",
    "                'span', class_='nl-price--total')\n",
    "            original_price = alt_original_price_element.text.strip(\n",
    "            ) if alt_original_price_element else 'N/A'\n",
    "\n",
    "        clearance_price = float(clearance_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if clearance_price != 'N/A' else None\n",
    "        original_price = float(original_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if original_price != 'N/A' else None\n",
    "\n",
    "        sale_product_data.append({\n",
    "            'Product Name': product_name,\n",
    "            'Original Price': original_price,\n",
    "            'Sale Price': clearance_price,\n",
    "            'Rating': rating,\n",
    "            'Product Code': product_code,\n",
    "            'Link': product_link,\n",
    "            'Image Link': product_image_link\n",
    "        })\n",
    "\n",
    "driver2.quit()\n",
    "\n",
    "print(f\"Total number of results: {total_results}\")\n",
    "print(f\"Total number of pages: {total_pages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data organizing, error handling\n",
    "sale_df = pd.DataFrame(sale_product_data)\n",
    "sale_df['Percentage Off'] = (\n",
    "    (sale_df['Original Price'] - sale_df['Sale Price']) / sale_df['Original Price']) * 100\n",
    "sale_df['Percentage Off'] = sale_df['Percentage Off'].fillna(0).round(2)\n",
    "sale_df['Product Category'] = sale_df['Image Link'].apply(extract_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED-ALERT-DEALS scraping. Code is nearly idential to the above.\n",
    "# scraping the sale section for additional data\n",
    "\n",
    "base_url = \"https://www.canadiantire.ca/en/promotions/red-alert-deals.html?page=\"\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--incognito\")\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"profile.default_content_setting_values.geolocation\": 1\n",
    "})\n",
    "\n",
    "service = Service(\n",
    "    \"C:\\Program Files\\Common Files\\ChromeDriver\\chromedriver.exe\")\n",
    "driver3 = webdriver.Chrome(service=service)\n",
    "\n",
    "driver3.get(base_url)\n",
    "time.sleep(5)\n",
    "html_content = driver3.page_source\n",
    "html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "total_results_element = html_soup.find('span', class_='nl-filters__results')\n",
    "total_results_text = total_results_element.text if total_results_element else '0'\n",
    "\n",
    "total_results = int(re.search(r'\\d+', total_results_text).group())\n",
    "\n",
    "items_per_page = 24\n",
    "total_pages = math.ceil(total_results / items_per_page)\n",
    "\n",
    "sale_product_data_2 = []\n",
    "\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    url = base_url + str(page_number)\n",
    "    driver3.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        not_right_now_button = WebDriverWait(driver3, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"kplDeclineButton\"))\n",
    "        )\n",
    "        not_right_now_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    html_content = driver3.page_source\n",
    "    html_soup = soup(html_content, 'html.parser')\n",
    "\n",
    "    sale_product_info2 = html_soup.find_all(class_='nl-product__content')\n",
    "\n",
    "    for product in sale_product_info2:\n",
    "        product_name_element = product.find(\n",
    "            'div', class_='nl-product-card__title')\n",
    "        original_price_element = product.find(\n",
    "            's', attrs={'aria-hidden': 'true'})\n",
    "        clearance_price_element = product.find(\n",
    "            'span', class_='nl-price--total--red')\n",
    "        rating_element = product.find('div', class_='bv_text')\n",
    "        image_element = product.find(\n",
    "            'div', class_='nl-product-card__image-wrap')\n",
    "        anchor_tag = product.find(\n",
    "            'a', class_='nl-product-card__no-button', href=True)\n",
    "        img_tag = product.find('img', attrs={'data-src': True})\n",
    "\n",
    "        product_name = product_name_element.text.strip() if product_name_element else 'N/A'\n",
    "        original_price = original_price_element.text.strip(\n",
    "        ) if original_price_element else 'N/A'\n",
    "        clearance_price = clearance_price_element.text.strip(\n",
    "        ) if clearance_price_element else 'N/A'\n",
    "        rating = rating_element.text.strip() if rating_element else None\n",
    "        product_code_element = product.find(\n",
    "            'p', class_='nl-product__code', attrs={'aria-hidden': 'true'})\n",
    "        product_code = product_code_element.get_text(\n",
    "            strip=True).lstrip('#') if product_code_element else 'N/A'\n",
    "        product_link = \"https://www.canadiantire.ca\" + \\\n",
    "            anchor_tag['href'] if anchor_tag is not None else 'N/A'\n",
    "        product_image_link = img_tag['data-src'] if img_tag and 'data-src' in img_tag.attrs else 'N/A'\n",
    "\n",
    "        if original_price == 'N/A':\n",
    "            alt_original_price_element = product.find(\n",
    "                'span', class_='nl-price--total')\n",
    "            original_price = alt_original_price_element.text.strip(\n",
    "            ) if alt_original_price_element else 'N/A'\n",
    "\n",
    "        clearance_price = float(clearance_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if clearance_price != 'N/A' else None\n",
    "        original_price = float(original_price.replace('Each', '').replace(\n",
    "            '$', '').replace(',', '')) if original_price != 'N/A' else None\n",
    "\n",
    "        sale_product_data_2.append({\n",
    "            'Product Name': product_name,\n",
    "            'Original Price': original_price,\n",
    "            'Sale Price': clearance_price,\n",
    "            'Rating': rating,\n",
    "            'Product Code': product_code,\n",
    "            'Link': product_link,\n",
    "            'Image Link': product_image_link\n",
    "        })\n",
    "\n",
    "driver3.quit()\n",
    "\n",
    "print(f\"Total number of results: {total_results}\")\n",
    "print(f\"Total number of pages: {total_pages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_df2 = pd.DataFrame(sale_product_data_2)\n",
    "sale_df2['Percentage Off'] = (\n",
    "    (sale_df2['Original Price'] - sale_df2['Sale Price']) / sale_df2['Original Price']) * 100\n",
    "sale_df2['Percentage Off'] = sale_df2['Percentage Off'].fillna(0).round(2)\n",
    "sale_df2['Product Category'] = sale_df2['Image Link'].apply(extract_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "print(len(clearance_df))\n",
    "clearance_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "print(len(sale_df))\n",
    "sale_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "print(len(sale_df2))\n",
    "sale_df2.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "clearance_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "sale_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "sale_df2.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer needed, I just used them to parse out the product type\n",
    "clearance_df.drop('Image Link', axis=1, inplace=True)\n",
    "sale_df.drop('Image Link', axis=1, inplace=True)\n",
    "sale_df2.drop('Image Link', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reordering columns so they make more sense to me.\n",
    "clearance_column_order = ['Product Name',\n",
    "                          'Original Price',\n",
    "                          'Clearance Price',\n",
    "                          'Percentage Off',\n",
    "                          'Product Category',\n",
    "                          'Product Code',\n",
    "                          'Rating',\n",
    "                          'Link']\n",
    "\n",
    "sale_column_order = ['Product Name',\n",
    "                     'Original Price',\n",
    "                     'Sale Price',\n",
    "                     'Percentage Off',\n",
    "                     'Product Category',\n",
    "                     'Product Code',\n",
    "                     'Rating',\n",
    "                     'Link']\n",
    "\n",
    "clearance_df = clearance_df.loc[:, clearance_column_order]\n",
    "sale_df = sale_df.loc[:, sale_column_order]\n",
    "sale_df2 = sale_df2.loc[:, sale_column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change astype in case I want to use this later\n",
    "clearance_df['Rating'] = clearance_df['Rating'].astype(float)\n",
    "sale_df['Rating'] = sale_df['Rating'].astype(float)\n",
    "sale_df2['Rating'] = sale_df2['Rating'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "clearance_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "sale_df.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking\n",
    "sale_df2.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing characters that were causing sql import issues.\n",
    "\n",
    "clearance_df[\"Product Name\"] = clearance_df[\"Product Name\"].str.replace(\n",
    "    \"'\", '')\n",
    "clearance_df[\"Product Name\"] = clearance_df[\"Product Name\"].str.replace(\n",
    "    \"Â®\", '')\n",
    "sale_df[\"Product Name\"] = sale_df[\"Product Name\"].str.replace(\"'\", '')\n",
    "sale_df[\"Product Name\"] = sale_df[\"Product Name\"].str.replace(\"Â®\", '')\n",
    "sale_df2[\"Product Name\"] = sale_df2[\"Product Name\"].str.replace(\"'\", '')\n",
    "sale_df2[\"Product Name\"] = sale_df2[\"Product Name\"].str.replace(\"Â®\", '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearance_df.to_csv(\"./data/clearance.csv\", index=False, mode='w')\n",
    "sale_df.to_csv(\"./data/sale.csv\", index=False, mode='w')\n",
    "sale_df2.to_csv(\"./data/sale2.csv\", index=False, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case I only want to work with all the sale products, not seperated by specific promotion\n",
    "allsales_df = pd.concat([sale_df, sale_df2], ignore_index=True)\n",
    "allsales_df.to_csv(\"./data/allsales.csv\", index=False, mode='w')\n",
    "\n",
    "allproducts_df = pd.concat(\n",
    "    [clearance_df, sale_df, sale_df2], ignore_index=True)\n",
    "allproducts_df.to_csv(\"./data/allproducts_df.csv\", index=False, mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I was thinking about saving the files with a datatime in case I wanted to do historical analysis at a later date.\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "clearance_df.to_csv(f\"./data/clearance_{current_date}.csv\", index=False)\n",
    "sale_df2.to_csv(f\"./data/sale2_{current_date}.csv\", index=False)\n",
    "allsales_df.to_csv(f\"./data/allsales_{current_date}.csv\", index=False)\n",
    "allproducts_df.to_csv(f\"./data/allproducts_{current_date}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection details for uploading to the server\n",
    "# Get the database connection details from environment variables\n",
    "username = os.environ.get('DB_USERNAME')\n",
    "password = os.environ.get('DB_PASSWORD')\n",
    "host = os.environ.get('DB_HOST')\n",
    "database = os.environ.get('DB_NAME')\n",
    "\n",
    "# Create the database connection URL\n",
    "# Create the URL to connect to the PostgreSQL database using the connection details\n",
    "url = f'postgresql://{username}:{password}@{host}/{database}'\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(url)\n",
    "\n",
    "# Create the metadata for defining the tables\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define the \"clearance\" table with SQLAlchemy\n",
    "# Specify the columns and their data types for the \"clearance\" table\n",
    "clearance_table = Table('clearance', metadata,\n",
    "                        Column('product_name', String),\n",
    "                        Column('original_price', Float),\n",
    "                        Column('clearance_price', Float),\n",
    "                        Column('percentage_off', Float),\n",
    "                        Column('product_category', String),\n",
    "                        Column('product_code', String),\n",
    "                        Column('rating', Float),\n",
    "                        Column('link', String),\n",
    "                        )\n",
    "\n",
    "# Define the \"sales\" table with SQLAlchemy\n",
    "# Specify the columns and their data types for the \"sales\" table\n",
    "sales_table = Table('sales', metadata,\n",
    "                    Column('product_name', String),\n",
    "                    Column('original_price', Float),\n",
    "                    Column('clearance_price', Float),\n",
    "                    Column('percentage_off', Float),\n",
    "                    Column('product_category', String),\n",
    "                    Column('product_code', String),\n",
    "                    Column('rating', Float),\n",
    "                    Column('link', String),\n",
    "                    )\n",
    "\n",
    "# Create the tables in the database if they don't exist\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Delete all rows from the \"clearance\" table before inserting new data so that we only have fresh deals.\n",
    "# Execute the DELETE statement to clear all rows from the \"clearance\" table\n",
    "engine.execute(clearance_table.delete())\n",
    "\n",
    "# Read clearance.csv and upload the data to the \"clearance\" table\n",
    "# Convert the CSV data into a list of dictionaries to be inserted into the table\n",
    "# Use None for empty fields in the database\n",
    "with open('data/clearance.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    data_to_insert = []\n",
    "    for row in csv_reader:\n",
    "        # convert the value in rows to a float if it is a non-empty string.\n",
    "        # If row is an empty string, it sets the field in the dictionary to None.\n",
    "        original_price = float(row[1]) if row[1] != '' else None\n",
    "        clearance_price = float(row[2]) if row[2] != '' else None\n",
    "        percentage_off = float(row[3]) if row[3] != '' else None\n",
    "        rating = float(row[6]) if row[6] != '' else None\n",
    "\n",
    "        data_to_insert.append({\n",
    "            \"product_name\": row[0],\n",
    "            \"original_price\": original_price,\n",
    "            \"clearance_price\": clearance_price,\n",
    "            \"percentage_off\": percentage_off,\n",
    "            \"product_category\": row[4],\n",
    "            \"product_code\": row[5],\n",
    "            \"rating\": rating,\n",
    "            \"link\": row[7]\n",
    "        })\n",
    "\n",
    "    # Insert the data into the \"clearance\" table\n",
    "    insert_query = clearance_table.insert()\n",
    "    engine.execute(insert_query, data_to_insert)\n",
    "\n",
    "# Delete all rows from the \"sales\" table before inserting new data\n",
    "# Execute the DELETE statement to clear all rows from the \"sales\" table\n",
    "engine.execute(sales_table.delete())\n",
    "\n",
    "# Read allsales.csv and upload the data to the \"sales\" table\n",
    "# Convert the CSV data into a list of dictionaries to be inserted into the table\n",
    "# Use None for empty fields in the database\n",
    "with open('data/allsales.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    sales_data_to_insert = []\n",
    "    for row in csv_reader:\n",
    "        original_price = float(row[1]) if row[1] != '' else None\n",
    "        clearance_price = float(row[2]) if row[2] != '' else None\n",
    "        percentage_off = float(row[3]) if row[3] != '' else None\n",
    "        rating = float(row[6]) if row[6] != '' else None\n",
    "\n",
    "        sales_data_to_insert.append({\n",
    "            \"product_name\": row[0],\n",
    "            \"original_price\": original_price,\n",
    "            \"clearance_price\": clearance_price,\n",
    "            \"percentage_off\": percentage_off,\n",
    "            \"product_category\": row[4],\n",
    "            \"product_code\": row[5],\n",
    "            \"rating\": rating,\n",
    "            \"link\": row[7]\n",
    "        })\n",
    "\n",
    "    # Insert the data into the \"sales\" table\n",
    "    sales_insert_query = sales_table.insert()\n",
    "    engine.execute(sales_insert_query, sales_data_to_insert)\n",
    "    engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next version options\n",
    "# option for using the dataframes directly instead of CSVs to push to the SQL Server.\n",
    "# beta not fully tested\n",
    "\n",
    "# username = os.environ.get('DB_USERNAME')\n",
    "# password = os.environ.get('DB_PASSWORD')\n",
    "# host = os.environ.get('DB_HOST')\n",
    "# database = os.environ.get('DB_NAME')\n",
    "\n",
    "# url = f'postgresql://{username}:{password}@{host}/{database}'\n",
    "# engine = create_engine(url)\n",
    "# metadata = MetaData()\n",
    "\n",
    "# clearance_table = Table('clearance', metadata,\n",
    "#     Column('product_name', String),\n",
    "#     Column('original_price', Float),\n",
    "#     Column('clearance_price', Float),\n",
    "#     Column('percentage_off', Float),\n",
    "#     Column('product_category', String),\n",
    "#     Column('product_code', String),\n",
    "#     Column('rating', Float),\n",
    "#     Column('link', String),\n",
    "# )\n",
    "\n",
    "# sales_table = Table('sales', metadata,\n",
    "#     Column('product_name', String),\n",
    "#     Column('original_price', Float),\n",
    "#     Column('clearance_price', Float),\n",
    "#     Column('percentage_off', Float),\n",
    "#     Column('product_category', String),\n",
    "#     Column('product_code', String),\n",
    "#     Column('rating', Float),\n",
    "#     Column('link', String),\n",
    "# )\n",
    "\n",
    "# metadata.create_all(engine)\n",
    "\n",
    "# clearance_data_to_insert = clearance_df.to_dict(orient='records')\n",
    "# sales_data_to_insert = allsales_df.to_dict(orient='records')\n",
    "\n",
    "# with engine.connect() as conn:\n",
    "#     # Delete all rows from the \"clearance\" table before inserting new data\n",
    "#     conn.execute(clearance_table.delete())\n",
    "\n",
    "#     # Insert the data into the \"clearance\" table\n",
    "#     conn.execute(clearance_table.insert(), clearance_data_to_insert)\n",
    "\n",
    "#     # Delete all rows from the \"sales\" table before inserting new data\n",
    "#     conn.execute(sales_table.delete())\n",
    "\n",
    "#     # Insert the data into the \"sales\" table\n",
    "#     conn.execute(sales_table.insert(), sales_data_to_insert)\n",
    "\n",
    "# # Dispose the engine to release resources\n",
    "# engine.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
